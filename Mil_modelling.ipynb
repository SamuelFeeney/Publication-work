{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Calling packages and assigning variables\n",
    "Here i call the necessary packages as well as assigning variables. Of note are the paths to collected data which will need to be changed for replication in another system"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import rdkit\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import gc\n",
    "from dask.distributed import Client\n",
    "from tpot import TPOTClassifier\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import MACCSkeys\n",
    "from mordred import Calculator, descriptors\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "try:\n",
    "    import misvm \n",
    "except:\n",
    "    !pip install -e git+https://github.com/garydoranjr/misvm.git#egg=misvm\n",
    "    print(\"\\n \\n Install complete, please restart kernal\")\n",
    "\n",
    "gc.enable()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Cleaning Biotransformer data\n",
    "This section is used to transform the input data such that it is usable for model building. This involves matching metabolite to parent molecules as well as finding\n",
    "thier canonical smiles. <br /><br />\n",
    "Additionally this section pre-calculates the encoding of each molecule for modeling to save on time, especially for subsequent runs"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def normalize_smiles(smi):      ## Converts each SMILES to an RDkit molecule then reconverts to SMILES. Ensures molecules with the same structure are the same SMILES\n",
    "    try:\n",
    "        smi_norm = Chem.MolToSmiles(Chem.MolFromSmiles(smi))\n",
    "        return smi_norm\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def parent_finder(smi):         ## Searches the \"smiles\" column of the \"data\" dataframe of the original molecules and normalises both, returning a match if found\n",
    "    for parent in data['smiles']:\n",
    "        try:\n",
    "            if Chem.MolToSmiles(Chem.MolFromSmiles(smi)) == Chem.MolToSmiles(Chem.MolFromSmiles(parent)):\n",
    "                return parent\n",
    "        except:\n",
    "            continue\n",
    "    return \"No parent found\"\n",
    "\n",
    "def get_ml_encoding(df, function=MACCSkeys.GenMACCSKeys):   ## returns a list, where each . Done to whole dataframe to allow for removing columns with NaN values\n",
    "    def number_check(x):            ## Checks if a value can be converted to a float. Used to remove non-numeric encoding\n",
    "        try:\n",
    "            float(x)\n",
    "            return x\n",
    "        except:\n",
    "            return \"broken\"\n",
    "\n",
    "    ## Generate encoding list from smiles\n",
    "    working_df = df.copy()                                                                     \n",
    "    working_df['encoding_list'] = working_df['smiles'].apply(lambda x: list(function(Chem.MolFromSmiles(x))))   \n",
    "    ## Create dataframe from encoding list\n",
    "    encoding_df = pd.DataFrame(working_df['encoding_list'].to_list())   \n",
    "    ## Cleaning Nan or non-numeric columns, as well as removing single value columns\n",
    "    encoding_df = encoding_df.applymap(number_check).dropna(axis =1, how = \"any\")  \n",
    "    encoding_df = encoding_df.drop(columns=encoding_df.columns[(encoding_df == 'broken').any()])\n",
    "    encoding_df = encoding_df[[c for c in list(encoding_df) if len(encoding_df[c].unique()) > 1]]                                           \n",
    "    ## Transform encoding dataframe into a list of lists. Can be used to generate a new column of the original dataframe                       \n",
    "    X = encoding_df.values.tolist()                                                                                                                       \n",
    "    return X\n",
    "\n",
    "def bag_parent(smiles,met_df,function):\n",
    "    ## Create dataframe from molecules with parent == smiles as well as the smiles molecule. Removes duplicates\n",
    "    mol_family          =   met_df[met_df[\"parent smiles\"]==smiles].append({'smiles':smiles},ignore_index=True).drop_duplicates(subset=[\"smiles\"])\n",
    "    ##  Encodes this family using above\n",
    "    mol_family_encoded  =   get_ml_encoding(df = mol_family, function = function)\n",
    "    return mol_family_encoded"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "if os.path.isfile(\"encoded_data.pk1\"):      ##  Checks if file already exists. Saves time and no changes are expected\n",
    "    print(\"Data already encoded\")\n",
    "\n",
    "else:\n",
    "    ##          Step 1: Load data into dataframes\n",
    "    data = pd.read_csv(\"selected_molecules.csv\")\n",
    "    metabolite_data = pd.read_csv(\"biotransformer_output_cyp1.csv\").append(pd.read_csv(\"biotransformer_output_phaseII.csv\"))\n",
    "\n",
    "    ##          Step 2: Normailizing metabolite smiles and matching to parent (approx 220 secs) \n",
    "    metabolite_data['smiles']           = metabolite_data['SMILES'].apply(lambda x: normalize_smiles(x)).dropna(axis=0,subset=['smiles'])\n",
    "    metabolite_data['parent smiles']    = metabolite_data['Precursor SMILES'].apply(lambda x:parent_finder(x))\n",
    "\n",
    "    ##          Step 3: Pre calculating encoding for molecules, requires evaluation of lists on loading csv (approx 110 secs)\n",
    "    data[\"MACCS\"] = get_ml_encoding(df = data, function = MACCSkeys.GenMACCSKeys)\n",
    "    data[\"RDKF\"] = get_ml_encoding(df = data, function =  Chem.RDKFingerprint)\n",
    "    data[\"MACCS_MIL\"] = data.apply(lambda row: bag_parent(smiles = row['smiles'], met_df = metabolite_data, function = MACCSkeys.GenMACCSKeys),axis=1)\n",
    "    data[\"RDKF_MIL\"] = data.apply(lambda row: bag_parent(smiles = row['smiles'], met_df = metabolite_data, function = Chem.RDKFingerprint),axis=1)\n",
    "    \n",
    "    ##          Step 3: Saved to a pickle, rather than a csv this stores the lists and is much faster to load (~10x)\n",
    "    data = data.drop([\"Molecule\"],axis=1)\n",
    "    data.to_pickle(\"encoded_data.pk1\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Data already encoded\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Defining functions\n",
    "This section is where i define functions for model development. <br /> If you're curious on how it is done please look here"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def check_if_tested(suffix,model_name,encoding):    ## Checking if this build/test has already been done. Saves on time if a run crashes\n",
    "    if not os.path.isfile(\"total_results.pk1\"): \n",
    "        already_complete = False\n",
    "    else:\n",
    "        results = pd.read_pickle(\"total_results.pk1\")\n",
    "        already_complete = ((results[\"fold\"].isin([suffix[\"fold\"]])) & (results[\"iteration\"].isin([suffix[\"iteration\"]])) & (results[\"model\"].isin([model_name])) & (results[\"encoding\"].isin([encoding]))).any()\n",
    "    return already_complete\n",
    "\n",
    "def build_test_mil_model(training_data,testing_data,MIL,encoding,suffix,save_model,model_name = \"\"):    ## Build and test a MIL model\n",
    "    already_complete = check_if_tested(suffix=suffix,encoding=encoding,model_name=model_name)\n",
    "    if not already_complete:\n",
    "        ##      Building model, note encoding already performed\n",
    "        bags = training_data[encoding+\"_MIL\"].to_list()\n",
    "        labels = training_data[\"Ames\"].apply(lambda x: x if x==1 else -1).to_list()\n",
    "        model = MIL                                                              \n",
    "        model.fit(bags,labels)    \n",
    "        ##      Testing model\n",
    "        bags = testing_data[encoding+\"_MIL\"].to_list()\n",
    "        labels = testing_data[\"Ames\"].apply(lambda x: x if x==1 else -1).to_list()\n",
    "        predictions = model.predict(bags)                                        \n",
    "        predicted_labels = list(map(pos_or_neg,predictions))                            \n",
    "        df = pd.DataFrame({\n",
    "            'predicted' : predictions,\n",
    "            'predicted labal' : predicted_labels,\n",
    "            'true label' : labels\n",
    "        })  \n",
    "        save_results(df = df, suffix = suffix, model = model_name, encoding = encoding)\n",
    "        if save_model:\n",
    "            save_models(model = model, path = \"/saved_models/\"+model_name+\"_\"+str(suffix[\"fold\"])+\"_\"+str(suffix[\"iteration\"]+\".sav\"))\n",
    "    else:\n",
    "        print(\"Already tested   fold:\",suffix[\"fold\"],\"   iteration:\",suffix[\"iteration\"],\"   model:\",model_name,\"   encoding:\",encoding)\n",
    "\n",
    "def build_test_ml_model(training_data,testing_data,encoding,ML,suffix,save_model):                      ## Build and test a machine learning model\n",
    "    already_complete = check_if_tested(suffix=suffix,encoding=encoding,model_name=\"TPOT\")\n",
    "    if not already_complete:\n",
    "        ##      Building model, note encoding already performed\n",
    "        instances = np.array(training_data[encoding].to_list())\n",
    "        labels = np.array(training_data[\"Ames\"].to_list())       \n",
    "        tpot_optimisation = ML                                                          \n",
    "        tpot_optimisation.fit(instances,labels)    \n",
    "        ##      Testing model\n",
    "        model = tpot_optimisation.fitted_pipeline_  ## This takes the best fitted pipeline developed\n",
    "        instances = testing_data[encoding].to_list()\n",
    "        true_labels = testing_data[\"Ames\"].to_list()       \n",
    "        predictions = model.predict(instances)                                   \n",
    "        predicted_labels = list(map(pos_or_neg,predictions))                            \n",
    "        df = pd.DataFrame({\n",
    "            'predicted' : predictions,\n",
    "            'predicted labal' : predicted_labels,\n",
    "            'true label' : true_labels\n",
    "        })   \n",
    "        save_results(df = df, suffix = suffix, model = \"TPOT\", encoding = encoding)  \n",
    "        if save_model:\n",
    "            save_models(model = model, path = \"/saved_models/TPOT_\"+str(suffix[\"fold\"])+\"_\"+str(suffix[\"iteration\"]+\".sav\"))\n",
    "    else:\n",
    "        print(\"Already tested   fold:\",suffix[\"fold\"],\"   iteration:\",suffix[\"iteration\"],\"   model:\",\"TPOT\",\"   encoding:\",encoding)\n",
    "\n",
    "def pos_or_neg(x):  ## Simple function used to translate predictions between MIL and ML into a single form\n",
    "    if x>0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def format_results(df,suffix,model,encoding):  ## adds informative columns to the df used for saving results \n",
    "    df[\"fold\"]  =   suffix[\"fold\"]\n",
    "    df[\"iteration\"] =   suffix[\"iteration\"]\n",
    "    df['index'] = df.index\n",
    "    df[\"model\"] =   model\n",
    "    df[\"encoding\"] =   encoding\n",
    "    return df\n",
    "\n",
    "def save_results(df,suffix,model,encoding):     ## saves results to a single pickle, adding to it or generating it\n",
    "    if not os.path.isfile(\"total_results.pk1\"):\n",
    "        df_formatted = format_results(df=df,suffix=suffix,model=model,encoding=encoding)\n",
    "        df_formatted.to_pickle(\"total_results.pk1\")\n",
    "    else:\n",
    "        total_results = pd.read_pickle(\"total_results.pk1\")\n",
    "        df_formatted = format_results(df=df,suffix=suffix,model=model,encoding=encoding)\n",
    "        total_results = total_results.append(df_formatted)\n",
    "        total_results.to_pickle(\"total_results.pk1\")\n",
    "        \n",
    "def save_models(model,path):                    ## Saves model to a path\n",
    "    pickle.dump(model, open(path, 'wb'))\n",
    "\n",
    "def develop_models(training_data,testing_data,suffix={\"fold\":\"\",\"iteration\":\"\"},encoding=\"MACCS\",save_model=False, dask=False):     ## single function to complete whole pipeline for a set of data to all expected models\n",
    "    ##      Step 0:     Checking that the encoding method described is expected\n",
    "    fps = [\"MACCS\",\"RDFP\"]\n",
    "    if not encoding in fps:\n",
    "        print('Please use expected encoding: [\"MACCS\", \"RDFP\"]')\n",
    "        return\n",
    "    \n",
    "    ##      Step 1:     Model generation\n",
    "    tested_mils =  [[\"MICA\", misvm.MICA(max_iters=50,verbose=False)],     \n",
    "                [\"MISVM\", misvm.MISVM(kernel='linear', C=1.0, max_iters=50,verbose=False)],\n",
    "                ['SIL', misvm.SIL(verbose=False)],\n",
    "                ['NSK', misvm.NSK(verbose=False)],\n",
    "                ['sMIL', misvm.sMIL(verbose=False)]]\n",
    "            ## note: Either as dask or non-dask TPOT can be used, defined in function variables\n",
    "    if dask:\n",
    "        tpot_model = TPOTClassifier(generations=10, population_size=500, cv=5, verbosity=2,use_dask=dask, n_jobs=-1)\n",
    "    else:\n",
    "        tpot_model = TPOTClassifier(generations=10, population_size=500, cv=5, verbosity=2, n_jobs=-1)\n",
    "\n",
    "    ##      Step 2:     Build and test models\n",
    "        # Iterate over the used MILs\n",
    "    for mil in tested_mils:\n",
    "        print(\"     Building and testing:\",mil[0],\"    fold:\",suffix[\"fold\"],\"    Iteration:\",suffix[\"iteration\"])\n",
    "        build_test_mil_model(training_data=training_data,testing_data=testing_data,suffix=suffix,MIL=mil[1],encoding=encoding,model_name=mil[0],save_model=save_model)\n",
    "        # Build and test TPOT model\n",
    "    print(\"     Building and testing: TPOT     fold:\",suffix[\"fold\"],\"    Iteration:\",suffix[\"iteration\"])\n",
    "    build_test_ml_model(training_data=training_data,testing_data=testing_data, ML = tpot_model,encoding=encoding,suffix=suffix,save_model=save_model)\n",
    "\n",
    "## Setting dask false, means that you can just unhash below to enable it\n",
    "dask = False"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Building models\n",
    "Here the above functions are used to build models. This section can be altered to build additional models if desired"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# ## Setting up Dask to allow parrallel training. If you don't want this please hash this out and change \"use_dask=True\" to \"use_dask=False\" in the develop models function\n",
    "# ################### #\n",
    "# client = Client()   #\n",
    "# client              #\n",
    "# dask = 4            #\n",
    "# ################### #"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## Selecting encoding method, can be changed to RDKF if desired\n",
    "encoding = \"MACCS\"\n",
    "\n",
    "##          Step 1: splitting data into a hold out validation dataset\n",
    "training_data, test_data = train_test_split(pd.read_pickle(\"encoded_data.pk1\"), test_size=0.2, stratify=pd.read_pickle(\"encoded_data.pk1\")[\"Ames\"], random_state=34783)\n",
    "training_data = training_data.reset_index(drop=True);   test_data = test_data.reset_index(drop=True)\n",
    "\n",
    "##          Step 2: Repeated stratified crossvalidation on training data\n",
    "rskf = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=6234794)\n",
    "for fold,[train_index, validation_index] in enumerate(rskf.split(training_data, training_data[\"Ames\"])):\n",
    "    train   =   training_data.iloc[train_index]\n",
    "    validation    =   training_data.iloc[validation_index]\n",
    "    develop_models(training_data=train,testing_data=validation,encoding = encoding,suffix={\"fold\":fold%10,\"iteration\":fold//10},save_model=False,dask=dask)\n",
    "    print(\"Done Fold\", \"    fold:\",fold%10,\"    iteration:\",fold//10)\n",
    "    gc.collect()\n",
    "\n",
    "# ##          Step 3: model building on training data against holdout test data\n",
    "# develop_models(training_data=train,testing_data=test_data,encoding = encoding,suffix={\"fold\":\"\",\"iteration\":\"Hold out test\"},save_model=True)\n",
    "\n",
    "# ## predict proba for some"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "     Building and testing: MICA     fold: 0     Iteration: 0\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "Can't get attribute '_unpickle_block' on <module 'pandas._libs.internals' from '/home/samuel/anaconda3/envs/my-rdkit-env/lib/python3.9/site-packages/pandas/_libs/internals.cpython-39-x86_64-linux-gnu.so'>",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-30eab7017b51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mtrain\u001b[0m   \u001b[0;34m=\u001b[0m   \u001b[0mtraining_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mvalidation\u001b[0m    \u001b[0;34m=\u001b[0m   \u001b[0mtraining_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalidation_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mdevelop_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtesting_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"fold\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"iteration\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done Fold\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"    fold:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"    iteration:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-7f85fa8d6a4f>\u001b[0m in \u001b[0;36mdevelop_models\u001b[0;34m(training_data, testing_data, suffix, encoding, save_model, dask)\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmil\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtested_mils\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"     Building and testing:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmil\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"    fold:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msuffix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"fold\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"    Iteration:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msuffix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"iteration\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0mbuild_test_mil_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtesting_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtesting_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msuffix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMIL\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmil\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmil\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0;31m# Build and test TPOT model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"     Building and testing: TPOT     fold:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msuffix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"fold\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"    Iteration:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msuffix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"iteration\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-7f85fa8d6a4f>\u001b[0m in \u001b[0;36mbuild_test_mil_model\u001b[0;34m(training_data, testing_data, MIL, encoding, suffix, save_model, model_name)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbuild_test_mil_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtesting_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMIL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msuffix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m## Build and test a MIL model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0malready_complete\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_if_tested\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msuffix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0malready_complete\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m##      Building model, note encoding already performed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-7f85fa8d6a4f>\u001b[0m in \u001b[0;36mcheck_if_tested\u001b[0;34m(suffix, model_name, encoding)\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0malready_complete\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"total_results.pk1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0malready_complete\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"fold\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msuffix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"fold\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"iteration\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msuffix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"iteration\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0malready_complete\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/my-rdkit-env/lib/python3.9/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    220\u001b[0m                 \u001b[0;31m#  \"No module named 'pandas.core.sparse.series'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                 \u001b[0;31m#  \"Can't get attribute '__nat_unpickle' on <module 'pandas._libs.tslib\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mUnicodeDecodeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;31m# e.g. can occur for files written in py27; see GH#28645 and GH#31988\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/my-rdkit-env/lib/python3.9/site-packages/pandas/compat/pickle_compat.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(fh, encoding, is_verbose)\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0mup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_verbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_verbose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/my-rdkit-env/lib/python3.9/pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1210\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1211\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1212\u001b[0;31m                 \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1213\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0m_Stop\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/my-rdkit-env/lib/python3.9/pickle.py\u001b[0m in \u001b[0;36mload_stack_global\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1535\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1536\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"STACK_GLOBAL requires str\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1537\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1538\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSTACK_GLOBAL\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_stack_global\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/my-rdkit-env/lib/python3.9/site-packages/pandas/compat/pickle_compat.py\u001b[0m in \u001b[0;36mfind_class\u001b[0;34m(self, module, name)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_class_locations_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/my-rdkit-env/lib/python3.9/pickle.py\u001b[0m in \u001b[0;36mfind_class\u001b[0;34m(self, module, name)\u001b[0m\n\u001b[1;32m   1579\u001b[0m         \u001b[0m__import__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1581\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_getattribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1582\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1583\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/my-rdkit-env/lib/python3.9/pickle.py\u001b[0m in \u001b[0;36m_getattribute\u001b[0;34m(obj, name)\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m             raise AttributeError(\"Can't get attribute {!r} on {!r}\"\n\u001b[0m\u001b[1;32m    332\u001b[0m                                  .format(name, obj)) from None\n\u001b[1;32m    333\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can't get attribute '_unpickle_block' on <module 'pandas._libs.internals' from '/home/samuel/anaconda3/envs/my-rdkit-env/lib/python3.9/site-packages/pandas/_libs/internals.cpython-39-x86_64-linux-gnu.so'>"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Validation\n",
    "Here the model results are assessed"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# develop_models(data,bt_data,validation_data,validation_metabolite_data,suffix=\"_validation\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Analysis\n",
    "Here the results of each fold are calculated as well as deviation within crossvalidation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def confusion_matrix(df):\n",
    "    TP = len(df[(df[\"predicted label\"] == 1) & (df[\"true label\"] == 1)])\n",
    "    TN = len(df[(df[\"predicted label\"] == 0) & (df[\"true label\"] == 0)])\n",
    "    FP = len(df[(df[\"predicted label\"] == 1) & (df[\"true label\"] == 0)])\n",
    "    FN = len(df[(df[\"predicted label\"] == 0) & (df[\"true label\"] == 1)])\n",
    "    return [TP,TN,FP,FN]\n",
    "\n",
    "def mean_accuracy(row):\n",
    "    acc = (row[\"TP\"]+row[\"TN\"])/(row[\"TP\"]+row[\"TN\"]+row[\"FP\"]+row[\"FN\"])\n",
    "    return acc\n",
    "\n",
    "def mean_sensitivity(row):\n",
    "    sens = row[\"TP\"]/(row[\"TP\"]+row[\"FP\"])\n",
    "    return sens\n",
    "\n",
    "def mean_specificity(row):\n",
    "    spec = row[\"TN\"]/(row[\"TN\"]+row[\"FN\"])\n",
    "    return spec\n",
    "\n",
    "def mean_F1(row):\n",
    "    f1 = (2*row[\"TP\"])/(2*row[\"TP\"]+row[\"FP\"]+row[\"FN\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "rslt_list = []\n",
    "\n",
    "crossvalidation_results = pd.read_pickle(\"total_results.pk1\")\n",
    "for iteration in crossvalidation_results[\"iteration\"].unique():\n",
    "    for fold in crossvalidation_results[\"fold\"].unique():\n",
    "        for model in crossvalidation_results[\"model\"].unique():\n",
    "            for encoding in crossvalidation_results[\"encoding\"].unique():\n",
    "                working_data = crossvalidation_results[(crossvalidation_results[\"fold\"]==fold)&(crossvalidation_results[\"iteration\"]==iteration)&(crossvalidation_results[\"model\"]==model)&(crossvalidation_results[\"encoding\"]==encoding)]\n",
    "                [TP,TN,FP,FN] = confusion_matrix(working_data)\n",
    "                rslt_list += [{\"encoding\":encoding, \"model\":model, \"fold\":fold, \"iteration\":iteration, \"TP\":TP, \"TN\":TN, \"FP\":FP, \"FN\":FN}]\n",
    "rslt_df = pd.Dataframe(rslt_list)\n",
    "\n",
    "mean_rslt_list = []\n",
    "for model in rslt_df[\"model\"].unique():\n",
    "    for encoding in rslt_df[\"encoding\"].unique():\n",
    "        working_data = rslt_df[(rslt_df[\"model\"]==model)&(rslt_df[\"encoding\"]==encoding)]\n",
    "        mean_rslt_list += [{\"encoding\":encoding, \"model\":model, \"Mean TP\":working_data[\"TP\"].mean(), \"Mean TN\":working_data[\"TN\"].mean(), \"Mean FP\":working_data[\"FP\"].mean(), \"Mean FN\":working_data[\"FN\"].mean()}]\n",
    "mean_rslt_df = pd.DataFrame(mean_rslt_list)\n",
    "mean_rslt_df[\"accuracy\"] = mean_rslt_df.apply(lambda x: mean_accuracy(x))\n",
    "mean_rslt_df[\"sensitivity\"] = mean_rslt_df.apply(lambda x: mean_sensitivity(x))\n",
    "mean_rslt_df[\"specificity\"] = mean_rslt_df.apply(lambda x: mean_specificity(x))\n",
    "mean_rslt_df[\"F1\"] = mean_rslt_df.apply(lambda x: mean_F1(x))\n",
    "# mean_rslt_df[\"AUROC\"] = mean_rslt_df.apply(lambda x: roc_auc_score())  #Need to redo with predict proba results\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('my-rdkit-env': conda)"
  },
  "interpreter": {
   "hash": "aa570c18d4c79ce07a0608da35f26cf3e1b27f1e4f5f00a1b9401f1c1693be53"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}