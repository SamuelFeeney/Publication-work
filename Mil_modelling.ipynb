{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Calling packages and assigning variables\n",
    "Here i call the necessary packages as well as assigning variables. Of note are the paths to collected data which will need to be changed for replication in another system"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import pandas as pd\n",
    "import misvm\n",
    "import rdkit\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import gc\n",
    "from dask.distributed import Client\n",
    "from tpot import TPOTClassifier\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import MACCSkeys\n",
    "from mordred import Calculator, descriptors\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "gc.enable()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Cleaning Biotransformer data\n",
    "This section is used to transform the input data such that it is usable for model building. This involves matching metabolite to parent molecules as well as finding\n",
    "thier canonical smiles. <br /><br />\n",
    "Additionally this section calculates the encoding of each molecule for modeling to save on time"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def normalize_smiles(smi):\n",
    "    try:\n",
    "        smi_norm = Chem.MolToSmiles(Chem.MolFromSmiles(smi))\n",
    "        return smi_norm\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def parent_finder(smi):\n",
    "    for parent in data['smiles']:\n",
    "        try:\n",
    "            if Chem.MolToSmiles(Chem.MolFromSmiles(smi)) == Chem.MolToSmiles(Chem.MolFromSmiles(parent)):\n",
    "                return parent\n",
    "        except:\n",
    "            continue\n",
    "    return \"No parent found\"\n",
    "\n",
    "def number_check(x):\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        return \"broken\"\n",
    "\n",
    "def get_ml_encoding(df, function=MACCSkeys.GenMACCSKeys):                                                                    \n",
    "    df1 = df.copy()                                                                     \n",
    "    df1['fp_list'] = df1['smiles'].apply(lambda x: list(function(Chem.MolFromSmiles(x))))     \n",
    "    df1 = df1.dropna(axis = 1, how = 'any')                                             \n",
    "\n",
    "    df2 = pd.DataFrame(df1['fp_list'].to_list())                                        \n",
    "    df2 = df2.applymap(number_check).dropna(axis =1, how = \"any\")                       \n",
    "    df2 = df2.drop(columns=df2.columns[(df2 == 'broken').any()])                        \n",
    "    X = [[int(i) for i in lst] for lst in df2.values.tolist()]                                                                                                                          \n",
    "    return X\n",
    "\n",
    "def bag_parent(smiles,met_df,function):\n",
    "    mol_family          =   met_df[met_df[\"parent smiles\"]==smiles].append({'smiles':smiles},ignore_index=True).drop_duplicates(subset=[\"smiles\"])\n",
    "    mol_family_encoded  =   get_ml_encoding(df = mol_family, function = function)\n",
    "    return mol_family_encoded"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "if os.path.isfile(\"encoded_data.pk1\"):\n",
    "    print(\"Data already encoded\")\n",
    "\n",
    "else:\n",
    "    data = pd.read_csv(\"selected_molecules.csv\")\n",
    "    metabolite_data = pd.read_csv(\"biotransformer_output_cyp1.csv\").append(pd.read_csv(\"biotransformer_output_phaseII.csv\"))\n",
    "\n",
    "    ##          Step 1: Normailizing metabolite smiles and matching to parent (approx 220 secs) \n",
    "    metabolite_data['smiles'] = metabolite_data['SMILES'].apply(lambda x: normalize_smiles(x))\n",
    "    metabolite_data = metabolite_data.dropna(axis=0,subset=['smiles'])\n",
    "    metabolite_data['parent smiles'] = metabolite_data['Precursor SMILES'].apply(lambda x:parent_finder(x))\n",
    "\n",
    "    ##          Step 2: Pre calculating encoding for molecules, requires evaluation of lists on loading csv (approx 110 secs)\n",
    "    data[\"MACCS\"] = get_ml_encoding(df = data, function = MACCSkeys.GenMACCSKeys)\n",
    "    data[\"RDKF\"] = get_ml_encoding(df = data, function =  Chem.RDKFingerprint)\n",
    "    data[\"MACCS_MIL\"] = data.apply(lambda row: bag_parent(smiles = row['smiles'], met_df = metabolite_data, function = MACCSkeys.GenMACCSKeys),axis=1)\n",
    "    data[\"RDKF_MIL\"] = data.apply(lambda row: bag_parent(smiles = row['smiles'], met_df = metabolite_data, function = Chem.RDKFingerprint),axis=1)\n",
    "    data = data.drop([\"Molecule\"],axis=1)\n",
    "    ##          Step 3: Saved to a pickle, rather than a csv this stores the lists and is much faster to load (~10x)\n",
    "    data.to_pickle(\"encoded_data.pk1\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Data already encoded\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Defining functions\n",
    "This section is where i define functions for model development. <br /> If you're curious on how it is done please look here"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def check_if_tested(suffix,model_name,encoding):\n",
    "    if not os.path.isfile(\"total_results.pk1\"): ## Checking if this has already been tested to save on time\n",
    "        already_complete = False\n",
    "    else:\n",
    "        results = pd.read_pickle(\"total_results.pk1\")\n",
    "        already_complete = ((results[\"fold\"].isin([suffix[\"fold\"]])) & (results[\"iteration\"].isin([suffix[\"iteration\"]])) & (results[\"model\"].isin([model_name])) & (results[\"encoding\"].isin([encoding]))).any()\n",
    "    return already_complete\n",
    "\n",
    "def build_test_mil_model(training_data,testing_data,MIL,encoding,suffix,save_model,model_name = \"\"):\n",
    "    already_complete = check_if_tested(suffix=suffix,encoding=encoding,model_name=model_name)\n",
    "    if not already_complete:\n",
    "        ##      Building model\n",
    "        bags = training_data[encoding+\"_MIL\"].to_list()\n",
    "        labels = training_data[\"Ames\"].apply(lambda x: x if x==1 else -1).to_list()\n",
    "        model = MIL                                                              \n",
    "        model.fit(bags,labels)    \n",
    "        ##      Testing model\n",
    "        bags = testing_data[encoding+\"_MIL\"].to_list()\n",
    "        labels = testing_data[\"Ames\"].apply(lambda x: x if x==1 else -1).to_list()\n",
    "        predictions = model.predict(bags)                                        \n",
    "        predicted_labels = list(map(pos_or_neg,predictions))                            \n",
    "        df = pd.DataFrame({\n",
    "            'predicted' : predictions,\n",
    "            'predicted labal' : predicted_labels,\n",
    "            'true label' : labels\n",
    "        })  \n",
    "        save_results(df = df, suffix = suffix, model = model_name, encoding = encoding)\n",
    "        if save_model:\n",
    "            save_models(model = model, path = \"/saved_models/\"+model_name+\"_\"+str(suffix[\"fold\"])+\"_\"+str(suffix[\"iteration\"]+\".sav\"))\n",
    "    else:\n",
    "        print(\"Already tested   fold:\",suffix[\"fold\"],\"   iteration:\",suffix[\"iteration\"],\"   model:\",model_name,\"   encoding:\",encoding)\n",
    "\n",
    "def build_test_ml_model(training_data,testing_data,encoding,ML,suffix,save_model):\n",
    "    already_complete = check_if_tested(suffix=suffix,encoding=encoding,model_name=\"TPOT\")\n",
    "    if not already_complete:\n",
    "        instances = np.array(training_data[encoding].to_list())\n",
    "        labels = np.array(training_data[\"Ames\"].to_list())       \n",
    "        tpot_optimisation = ML                                                          \n",
    "        tpot_optimisation.fit(instances,labels)    \n",
    "        model = tpot_optimisation.fitted_pipeline_                                                                 \n",
    "\n",
    "        instances = testing_data[encoding].to_list()\n",
    "        true_labels = testing_data[\"Ames\"].to_list()       \n",
    "        predictions = model.predict(instances)                                   \n",
    "        predicted_labels = list(map(pos_or_neg,predictions))                            \n",
    "        df = pd.DataFrame({\n",
    "            'predicted' : predictions,\n",
    "            'predicted labal' : predicted_labels,\n",
    "            'true label' : true_labels\n",
    "        })   \n",
    "        save_results(df = df, suffix = suffix, model = \"TPOT\", encoding = encoding)  \n",
    "        if save_model:\n",
    "            save_models(model = model, path = \"/saved_models/TPOT_\"+str(suffix[\"fold\"])+\"_\"+str(suffix[\"iteration\"]+\".sav\"))\n",
    "\n",
    "    else:\n",
    "        print(\"Already tested   fold:\",suffix[\"fold\"],\"   iteration:\",suffix[\"iteration\"],\"   model:\",\"TPOT\",\"   encoding:\",encoding)\n",
    "\n",
    "def pos_or_neg(x):\n",
    "    if x>0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def format_results(df,suffix,model,encoding):\n",
    "    df[\"fold\"]  =   suffix[\"fold\"]\n",
    "    df[\"iteration\"] =   suffix[\"iteration\"]\n",
    "    df['index'] = df.index\n",
    "    df[\"model\"] =   model\n",
    "    df[\"encoding\"] =   encoding\n",
    "    return df\n",
    "\n",
    "def save_results(df,suffix,model,encoding):\n",
    "    if not os.path.isfile(\"total_results.pk1\"):\n",
    "        df_formatted = format_results(df=df,suffix=suffix,model=model,encoding=encoding)\n",
    "        df_formatted.to_pickle(\"total_results.pk1\")\n",
    "    else:\n",
    "        total_results = pd.read_pickle(\"total_results.pk1\")\n",
    "        df_formatted = format_results(df=df,suffix=suffix,model=model,encoding=encoding)\n",
    "        total_results = total_results.append(df_formatted)\n",
    "        total_results.to_pickle(\"total_results.pk1\")\n",
    "        \n",
    "def save_models(model,path):\n",
    "    pickle.dump(model, open(path, 'wb'))\n",
    "\n",
    "def develop_models(training_data,testing_data,suffix={\"fold\":\"\",\"iteration\":\"\"},encoding=\"MACCS\",save_model=False):\n",
    "    tested_mils =  [[\"MICA\", misvm.MICA(max_iters=50,verbose=False)],     \n",
    "                [\"MISVM\", misvm.MISVM(kernel='linear', C=1.0, max_iters=50,verbose=False)],\n",
    "                ['SIL', misvm.SIL(verbose=False)],\n",
    "                ['NSK', misvm.NSK(verbose=False)],\n",
    "                ['sMIL', misvm.sMIL(verbose=False)]]\n",
    "    # tpot_model = TPOTClassifier(generations=10, population_size=500, cv=5, verbosity=2,use_dask=True, n_jobs=-1)\n",
    "    tpot_model = TPOTClassifier(generations=10, population_size=500, cv=5, verbosity=2)\n",
    "\n",
    "    fps = [\"MACCS\",\"RDFP\"]\n",
    "    if not encoding in fps:\n",
    "        print('Please use expected encoding: [\"MACCS\", \"RDFP\"]')\n",
    "        return\n",
    "    \n",
    "    # Iterate over the used MILs\n",
    "    for mil in tested_mils:\n",
    "        print(\"     Building and testing:\",mil[0],\"    fold:\",suffix[\"fold\"],\"    Iteration:\",suffix[\"iteration\"])\n",
    "        build_test_mil_model(training_data=training_data,testing_data=testing_data,suffix=suffix,MIL=mil[1],encoding=encoding,model_name=mil[0],save_model=save_model)\n",
    "    \n",
    "    # Build and test TPOT model\n",
    "    print(\"     Building and testing: TPOT     fold:\",suffix[\"fold\"],\"    Iteration:\",suffix[\"iteration\"])\n",
    "    build_test_ml_model(training_data=training_data,testing_data=testing_data, ML = tpot_model,encoding=encoding,suffix=suffix,save_model=save_model)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Building models\n",
    "Here the above functions are used to build models. This section can be altered to build additional models if desired"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "## Setting up Dask to allow parrallel training. If you don't want this please hash this out and change \"use_dask=True\" to \"use_dask=False\" in the develop models function\n",
    "# client = Client()\n",
    "# client"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "## Selecting encoding method, can be changed to RDKF if desired\n",
    "encoding = \"MACCS\"\n",
    "\n",
    "##          Step 1: splitting data into a hold out validation dataset\n",
    "training_data, validation_data = train_test_split(pd.read_pickle(\"encoded_data.pk1\"), test_size=0.2, stratify=pd.read_pickle(\"encoded_data.pk1\")[\"Ames\"], random_state=34783)\n",
    "training_data = training_data.reset_index(drop=True);   validation_data = validation_data.reset_index(drop=True)\n",
    "\n",
    "##          Step 2: Repeated stratified crossvalidation on training data\n",
    "rskf = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=6234794)\n",
    "for fold,[train_index, test_index] in enumerate(rskf.split(training_data, training_data[\"Ames\"])):\n",
    "    train   =   training_data.iloc[train_index]\n",
    "    test    =   training_data.iloc[test_index]\n",
    "    develop_models(training_data=train,testing_data=test,encoding = encoding,suffix={\"fold\":fold%10,\"iteration\":fold//10},save_model=False)\n",
    "    print(\"Done Fold\", \"    fold:\",fold%10,\"    iteration:\",fold//10)\n",
    "    gc.collect()\n",
    "\n",
    "# ##          Step 3: model building on training data against holdout validation data\n",
    "# develop_models(training_data=train,testing_data=test,encoding = encoding,suffix={\"fold\":\"\",\"iteration\":\"validation\"},save_model=True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "     Building and testing: MICA     fold: 0     Iteration: 0\n",
      "Already tested   fold: 0    iteration: 0    model: MICA    encoding: MACCS\n",
      "     Building and testing: MISVM     fold: 0     Iteration: 0\n",
      "Already tested   fold: 0    iteration: 0    model: MISVM    encoding: MACCS\n",
      "     Building and testing: SIL     fold: 0     Iteration: 0\n",
      "Already tested   fold: 0    iteration: 0    model: SIL    encoding: MACCS\n",
      "     Building and testing: NSK     fold: 0     Iteration: 0\n",
      "Already tested   fold: 0    iteration: 0    model: NSK    encoding: MACCS\n",
      "     Building and testing: sMIL     fold: 0     Iteration: 0\n",
      "Already tested   fold: 0    iteration: 0    model: sMIL    encoding: MACCS\n",
      "     Building and testing: TPOT     fold: 0     Iteration: 0\n",
      "Already tested   fold: 0    iteration: 0    model: TPOT    encoding: MACCS\n",
      "Done Fold     fold: 0     iteration: 0\n",
      "     Building and testing: MICA     fold: 1     Iteration: 0\n",
      "Already tested   fold: 1    iteration: 0    model: MICA    encoding: MACCS\n",
      "     Building and testing: MISVM     fold: 1     Iteration: 0\n",
      "Already tested   fold: 1    iteration: 0    model: MISVM    encoding: MACCS\n",
      "     Building and testing: SIL     fold: 1     Iteration: 0\n",
      "Already tested   fold: 1    iteration: 0    model: SIL    encoding: MACCS\n",
      "     Building and testing: NSK     fold: 1     Iteration: 0\n",
      "Already tested   fold: 1    iteration: 0    model: NSK    encoding: MACCS\n",
      "     Building and testing: sMIL     fold: 1     Iteration: 0\n",
      "Already tested   fold: 1    iteration: 0    model: sMIL    encoding: MACCS\n",
      "     Building and testing: TPOT     fold: 1     Iteration: 0\n",
      "Already tested   fold: 1    iteration: 0    model: TPOT    encoding: MACCS\n",
      "Done Fold     fold: 1     iteration: 0\n",
      "     Building and testing: MICA     fold: 2     Iteration: 0\n",
      "Already tested   fold: 2    iteration: 0    model: MICA    encoding: MACCS\n",
      "     Building and testing: MISVM     fold: 2     Iteration: 0\n",
      "Already tested   fold: 2    iteration: 0    model: MISVM    encoding: MACCS\n",
      "     Building and testing: SIL     fold: 2     Iteration: 0\n",
      "Already tested   fold: 2    iteration: 0    model: SIL    encoding: MACCS\n",
      "     Building and testing: NSK     fold: 2     Iteration: 0\n",
      "Already tested   fold: 2    iteration: 0    model: NSK    encoding: MACCS\n",
      "     Building and testing: sMIL     fold: 2     Iteration: 0\n",
      "Already tested   fold: 2    iteration: 0    model: sMIL    encoding: MACCS\n",
      "     Building and testing: TPOT     fold: 2     Iteration: 0\n",
      "Already tested   fold: 2    iteration: 0    model: TPOT    encoding: MACCS\n",
      "Done Fold     fold: 2     iteration: 0\n",
      "     Building and testing: MICA     fold: 3     Iteration: 0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Validation\n",
    "Here the model results are assessed"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# develop_models(data,bt_data,validation_data,validation_metabolite_data,suffix=\"_validation\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Analysis\n",
    "Here the results of each fold are calculated as well as deviation within crossvalidation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def confusion_matrix(df):\n",
    "    TP = len(df[(df[\"predicted label\"] == 1) & (df[\"true label\"] == 1)])\n",
    "    TN = len(df[(df[\"predicted label\"] == 0) & (df[\"true label\"] == 0)])\n",
    "    FP = len(df[(df[\"predicted label\"] == 1) & (df[\"true label\"] == 0)])\n",
    "    FN = len(df[(df[\"predicted label\"] == 0) & (df[\"true label\"] == 1)])\n",
    "    return [TP,TN,FP,FN]\n",
    "\n",
    "def mean_accuracy(row):\n",
    "    acc = (row[\"TP\"]+row[\"TN\"])/(row[\"TP\"]+row[\"TN\"]+row[\"FP\"]+row[\"FN\"])\n",
    "    return acc\n",
    "\n",
    "def mean_sensitivity(row):\n",
    "    sens = row[\"TP\"]/(row[\"TP\"]+row[\"FP\"])\n",
    "    return sens\n",
    "\n",
    "def mean_specificity(row):\n",
    "    spec = row[\"TN\"]/(row[\"TN\"]+row[\"FN\"])\n",
    "    return spec\n",
    "\n",
    "def mean_F1(row):\n",
    "    f1 = (2*row[\"TP\"])/(2*row[\"TP\"]+row[\"FP\"]+row[\"FN\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "rslt_list = []\n",
    "\n",
    "crossvalidation_results = pd.read_pickle(\"total_results.pk1\")\n",
    "for iteration in crossvalidation_results[\"iteration\"].unique():\n",
    "    for fold in crossvalidation_results[\"fold\"].unique():\n",
    "        for model in crossvalidation_results[\"model\"].unique():\n",
    "            for encoding in crossvalidation_results[\"encoding\"].unique():\n",
    "                working_data = crossvalidation_results[(crossvalidation_results[\"fold\"]==fold)&(crossvalidation_results[\"iteration\"]==iteration)&(crossvalidation_results[\"model\"]==model)&(crossvalidation_results[\"encoding\"]==encoding)]\n",
    "                [TP,TN,FP,FN] = confusion_matrix(working_data)\n",
    "                rslt_list += [{\"encoding\":encoding, \"model\":model, \"fold\":fold, \"iteration\":iteration, \"TP\":TP, \"TN\":TN, \"FP\":FP, \"FN\":FN}]\n",
    "rslt_df = pd.Dataframe(rslt_list)\n",
    "\n",
    "mean_rslt_list = []\n",
    "for model in rslt_df[\"model\"].unique():\n",
    "    for encoding in rslt_df[\"encoding\"].unique():\n",
    "        working_data = rslt_df[(rslt_df[\"model\"]==model)&(rslt_df[\"encoding\"]==encoding)]\n",
    "        mean_rslt_list += [{\"encoding\":encoding, \"model\":model, \"Mean TP\":working_data[\"TP\"].mean(), \"Mean TN\":working_data[\"TN\"].mean(), \"Mean FP\":working_data[\"FP\"].mean(), \"Mean FN\":working_data[\"FN\"].mean()}]\n",
    "mean_rslt_df = pd.DataFrame(mean_rslt_list)\n",
    "mean_rslt_df[\"accuracy\"] = mean_rslt_df.apply(lambda x: mean_accuracy(x))\n",
    "mean_rslt_df[\"sensitivity\"] = mean_rslt_df.apply(lambda x: mean_sensitivity(x))\n",
    "mean_rslt_df[\"specificity\"] = mean_rslt_df.apply(lambda x: mean_specificity(x))\n",
    "mean_rslt_df[\"F1\"] = mean_rslt_df.apply(lambda x: mean_F1(x))\n",
    "# mean_rslt_df[\"AUROC\"] = mean_rslt_df.apply(lambda x: roc_auc_score())  #Need to redo with predict proba results\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('my-rdkit-env': conda)"
  },
  "interpreter": {
   "hash": "aa570c18d4c79ce07a0608da35f26cf3e1b27f1e4f5f00a1b9401f1c1693be53"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}